# Week 8: Multimodal LLM â€” Tracks A & B

## Overview

This part of the Week 8 Multimodal LLM lab covers two complementary tracks:

### **Track A â€” Voice-Interactive LLM**
Speech â†’ Text â†’ LLM â†’ Speech  
Converts spoken questions into transcribed text, sends them through a local LLM (TinyLlama 1.1B-Chat), and synthesizes audio responses with gTTS.

### **Track B â€” Conversational Data Visualization**
Natural-language â†’ Chart generation.  
Accepts text queries like *â€œPlot accuracy by game numberâ€* and uses a validated plot-spec mapping to generate safe Matplotlib visualizations.

Both tracks extend the Week 7 model into multimodal interaction pipelines that can later be integrated into **Track Câ€™s router** or a Streamlit frontend.

---

## ğŸ™ï¸ Track A Pipeline: Speech â†’ LLM â†’ Speech

| Stage | Component | Description |
|--------|------------|-------------|
| ğŸ¤ **Speech Input** | `openai-whisper` | Transcribes `.wav` audio into text. |
| ğŸ§  **Reasoning** | `TinyLlama/TinyLlama-1.1B-Chat-v1.0` | Generates concise, factual answers to transcribed queries. |
| ğŸ”Š **Speech Output** | `gTTS` (Text-to-Speech) | Synthesizes the modelâ€™s text answer into spoken audio. |

**Example Interaction:**
- **Input (audio):** â€œWhat is the most powerful piece in chess?â€
- **Output (audio):** â€œThe queen is the most powerful piece in chess because it can move any number of squares in any direction.â€

---

## ğŸ“Š Track B Pipeline: Natural Language â†’ Matplotlib Visualization

| Stage | Component |
|--------|------------|
| ğŸ’¬ **NL Prompt** | Example: â€œPlot move-prediction accuracy by game number.â€ |
| ğŸ§© **Spec Mapping** | Maps NL query to safe `{x, y}` plot specification. |
| ğŸ“ˆ **Plot Generation** | `matplotlib.pyplot` â€” Single-figure plots, default style (no seaborn or color customization). |


