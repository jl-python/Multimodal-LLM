# Multimodal-LLM
This project engages an LLM and examines its performance on speech, visuals, and interaction. A routing method is also implemented in to a Streamlit app where the user interact with the LLM for multi purpose uses.

  - There are 2 tracks A&B and C
      - Track A&B a notebook for metrics of LLM + Speech + Visual Tools
      - Track C is a LLM tool router packaged into a streamlit app
  - Both tracks contain their own env, run_config, & README files
  - Results and Report of this assignment can be found on the main page
